---
layout: post
title: Netty
description: 解析Netty
category: blog
---

## netty是什么

netty是一个非阻塞IO模型的客户端、服务器网络框架, 它提供了一个全新的方式去开发网络应用，
主要是他抽象了复杂的基础组件和提供了易用的api接口，这样就解耦了网络处理和业务逻辑. (?)

如图揭示了netty框架一览：

![netty_framework](/images/netty.png)

## netty VS 原生的java NIO模型

netty也是基于原生的java NIO完成的非阻塞通信，但是在此基础之上又补充了一些java NIO的不足之处

* 跨平台和版本兼容性问题

java NIO的一些接口都是native函数，依赖于低层操作系统的实现
java NIO在JDK6发布，java NIO2在JDK7发布，存在版本兼容性问题
java NIO2不支持UDP通信，仅支持TCP通信

* ByteBuffer没有高层封装

原生ByteBuffer的功能较弱，netty自己重写了它

* 数据分散和聚集有内存溢出风险

一个channel可以同时写入到多个ByteBuffer，也可以同时从多个ByteBuffer里面读取数据
但是JDK7有OOM风险

* 解决epoll bug

selector的native操作实现一般是用epoll，但是epoll低层会有Bug，造成服务器select()函数
不管有无请求到达直接返回，导致SocketServer一直while无线循环，这种空转会极其消耗CPU资源
Netty对空转现象进行计数，当到达一个值时认为发生了epoll bug，则重建新的selector，销毁旧的selector

## Reactor线程模型

貌似也是一个链接对应一个Channel，一个Channel对应一个EventLoop，
但是多个Channel可以注册到相同的EventLoop，每个EventLoop对应一个单独的Thread处理线程

ChannleHandler的设计类似于Servlet的工作模式

一般网络服务器使用NIO，数据库访问需要使用OIO(old IO阻塞式的)

用户线程，IO线程

## 传输模型使用场景

### OIO阻塞式通信

每个connection对应一个处理Thread，适合低并发连接。一般认为低于1000的并发数就是低并发，
但是OIO可以处理1万以下的并发连接.
由于一个进程的所拥有线程数有限制，并且一个进程的栈空间有限制，不允许无限的生成线程
因此这种方案无法满足高性能、高并发场景

### 优化OIO

使用线程池的方式管理connection对应的处理线程。首先线程池的大小是有限制的，当线程池中的
线程被消耗完后新建立的future会排队等待；而由于每个线程采用阻塞式的方式读取数据，
阻塞的时间取决于网络状况和应用程序的处理能力，风险较大；当出现大面积的线程阻塞状态时，
排队的待处理线程会越来越多，当队列积满后，后续入队的操作将被阻塞，此时因为只有一个Acceptor
线程处理客户端接入，则会造成客户端(客户端同样采用OIO)大量的连接超时，客户端认为服务端崩溃了。

### 为什么会阻塞

在阻塞式通信过程中，当对Socket的输入流进行读取操作的时候，它会一直阻塞下去直到发生如下
三种事情。

* 有数据可读
* 可用数据已经读取完毕
* 发生空指针或者IO异常

这意味着当对方发送请求或者应对消息比较慢，或者网络传输比较慢时，读取输入流一方的
通信线程将被长时间阻塞，如果对方要60s才能够将数据发送完毕，读取一方的IO线程也将被
同步阻塞60s，在此期间，其他的接入消息只能在消息队列中排队。

在优化的OIO中只是在每次client建立连接后就分配一个连接处理线程，该线程做的第一件事情
就是无限循环读取

### NIO

首先，客户端如果采用NIO发起连接，则连接操作是异步的, 客户端不会被阻塞

在NIO库中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的；在写入
数据时，也是写入到缓冲区中，区别于OIO中直接会调系统级阻塞IO方法。
真正的缓冲区中的数据从用户区写入到内核区是异步完成的，应用程序不需要关系，
没有读写数据时处理程序不会等待而是直接返回，这样IO通信线程就可以处理其他的链路

Selector低层使用epoll模型，没有操作系统的连接句柄数限制

### AIO

对NIO做了高层封装而已，使用起来更方面
客户端和服务器低层的回调通知都是使用的ThreadPoolExecutor模型，不需要开发人员手动的建立线程对象

## ByteBuf数据模型

Netty冲定义了相对于JDK ByteBuffer的ByteBuf，但是使用起来比ByteBuf更简单，比如读写数据时不需要
手动flip

从内存分配角度看，ByteBuf分为两类：

- 堆内存字节缓存区

优点是内存的分配和回收速度快，可以被JVM自动回收；
缺点是如果做Socket的IO读写，需要额外的做一次内存复制，将堆内存对应的缓冲区复制到
内核Channel中，性能会有一定程度的下降

- 直接内存字节缓冲区

堆外内存分配，它的分配和回收速度回慢一些，但是它做Socket Channel的读写时由于少了
一次内存复制，速度比堆快
Netty使用内存池pool技术来负责直接内存方式的分配和回收工作

由于各有优势，Netty采用了混合使用策略，在IO通信线程的读写缓存区使用DirectByteBuf,
后端业务信息的编解码模块使用HeapByteBuf，这样组合到达性能最优

对于一个数组来说，ByteBuf支持空间的自动扩展，比如对象初始化的大小为100，但是一开始
只是分配了10个大小的长度，随着ByteBuf频繁的读写，原始对象的空间逐渐扩展，直到最大值；
每当当前的空间不满足需求时，都是重新申请一个新的ByteBuf，然后将旧数据copy到新对象中，
废弃掉原有的对象；对象的申请和销毁是很耗时间的，事实上对应一个ByteBuf来说，可以重用
读取完毕的空间，采用本地内存复制转移操作来实现, 删除从0到readIndex之前空间，剩余的数据
直接往前移，这样就增加了可写空间范围。

## 事件驱动

Netty基于事件驱动，可以理解为当Channel进行IO操作时会产生对应的IO事件，然后驱动事件在
ChannelPipeline中传播，由对应的ChannelHandler对事件进行拦截和处理，不关心的事件
可以直接忽略。采用事件驱动的方式可以非常轻松的通过事件定义来划分事件拦截切面，方便
业务的定制和功能扩展, 相比AOP，其性能更高，但是功能却基本等价。

每当服务器接入一个新的客户端连接NioSocketChannel时，都会调用childEventLoopGroup方法
获取EventLoopGroup线程组，用于给NioSocketChannel分配Reactor线程EventLoop

## ChannelPipeline和ChannelHandler

Netty的ChannelPipeline和ChannleHandler机制类似于Servlet和Filter过滤器, 这类拦截器实际上
是职责链模式的一种变形，主要是为了方便事件的拦截和用户业务逻辑的定制。

Servlet Filter是JEE Web应用程序级的Java代码组件，它能够以声明的方式插入HTTP请求响应
的处理过程中，用于拦截请求和响应，以便能够查看、提取或以某种方式操作正在客户端和服务器之间
交换的数据。拦截器封装了业务定制逻辑，能够实现对Web应用程序的预处理和事后处理。

过滤器提供了一种面向对象的模块化机制，用来将公共任务封装到可插入的组件中。这些组件通过
Web部署文件(web.xml)声明，可以方便地添加和删除过滤器。

区别是，Netty中的事件都是定义好的，想自定义自己的拦截器，无非是继承默认的ChannelHandlerAdapter
重定义感兴趣的方法(也就是针对指定的事件处理)，每个事件对应于一个方法

每个Channel对应一个独立的ChannelPipeline, ChannelPipeline可以理解为ChannleHandler的容器
ChannelPipeline是线程安全的，但是ChannelHandler不是线程安全的;
一个Channel可能会产品多个业务线程，多个业务线程可以并发的操作ChannelPipeline;
理论上，在Servlet中不会出现动态修改Servlet的需求，因此Servlet设计时一般就是非线程安全的，
但是在Channel处理中允许动态修改ChannelPipeline，存在着IO线程和用户业务线程、业务线程之间
对ChannelPipeline的并发访问(为啥？)，因此把ChannelPipeline设计为线程安全的

一个ChannelHandler实例可以被添加到多个ChannelPipeline中，ChannleHandler在每个ChannelPipeline
中的对应于一个单独的ChannleHandlerContext

## TCP粘包和解码器

在TCP传输过程中，数据已流的方式存在，在网络层由于各种原因会出现一个数据流可能携带多个包，
或者一个包太大被拆分成多个包发送的情况；
例如：
1. 应用程序write写入的字节大小大于socket发送缓冲区大小
2. TCP自身的MSS分段
3. 以太网帧的payload大于MTU进行IP分片

针对TCP粘包、拆包问题，需要后端程序手动的做包内数据的区分和合并, 一般采用以下4中方式：

1. 消息本身有固定长度，则累计读取长度总和为定长LEN的包长后就认为读取到了一个完整的消息。
2. 将回车换行符作为消息结束符，例如FTP协议纯文本一般采用这种方式
3. 使用特殊的分隔符作为消息的结束标志，回车换行符就是一种特殊的结束分隔符
4. 在消息头中定义长度字段来标志消息的总长度

HTTP是怎么做的包拆解和合并?

原始的字节流通过挂载的不同的Decoder解码器转化为适用的待处理对象，例如：
如果是处理的http协议，则需要适用HttpRequestDecoder, 数据转换为HttpRequest对象
如果是protoBuf协议，则需要使用ProtoBufDecoder


